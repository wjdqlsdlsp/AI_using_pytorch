{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "과제1_선형회귀 구현하기.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0Frj9xPnr9JmOHScFK1hJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjdqlsdlsp/AI_using_pytorch/blob/main/%EA%B3%BC%EC%A0%9C1_%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80_%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X80Umh6Wcwlc",
        "outputId": "97d0d015-4f3c-4e05-cc53-0b29f4055976"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0bf3e3dbf0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxbqEq_Fc0of"
      },
      "source": [
        "X_train = torch.FloatTensor([[-10, 0, -8, -8],\n",
        "            [-4, -3,  9,  3],\n",
        "            [-7,  9, 10,  4],\n",
        "            [-6, -4,  2,  3],\n",
        "            [-6, -9, -9,  1],\n",
        "            [-2,  5, -7, -2],\n",
        "            [-9, -2, -3, -3],\n",
        "            [9,  -4,  6,  4],\n",
        "            [9,  -1, -9, -6],\n",
        "            [1, -9, -11,  3]])\n",
        "\n",
        "y_train = torch.FloatTensor([-2.0, -53.9, -21.1, -36.7, -15.2, 42.9, -25.7, -11.4, 56.0, 7.2])\n",
        "y_train = y_train.reshape(-1, 1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgqy_TgtgHLU"
      },
      "source": [
        "# 1. class를 통해 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMiOnJ8KdJUc"
      },
      "source": [
        "class LRModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(4,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = LRModel()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfVoQIU5dbLu",
        "outputId": "ba207892-50c6-4d70-f823-c8b4d4632464"
      },
      "source": [
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for i in range(1000):\n",
        "    pred = model(X_train)\n",
        "    cost = F.mse_loss(pred, y_train)\n",
        "\n",
        "    opt.zero_grad()\n",
        "    cost.backward()\n",
        "    opt.step()\n",
        "\n",
        "    if i % 100 ==0:\n",
        "        print(\"Epoch : \",i, \"Cost\", cost.item())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :  0 Cost 1103.8489990234375\n",
            "Epoch :  100 Cost 4.56959867477417\n",
            "Epoch :  200 Cost 4.517507553100586\n",
            "Epoch :  300 Cost 4.514824390411377\n",
            "Epoch :  400 Cost 4.514693260192871\n",
            "Epoch :  500 Cost 4.514683723449707\n",
            "Epoch :  600 Cost 4.514683246612549\n",
            "Epoch :  700 Cost 4.514685153961182\n",
            "Epoch :  800 Cost 4.514681816101074\n",
            "Epoch :  900 Cost 4.514685153961182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxef5ht4gJUK"
      },
      "source": [
        "# 2. class를 사용하지 않고 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sUnmXzaeM3J",
        "outputId": "44a38409-5ba2-433f-8246-fedb9ceb9761"
      },
      "source": [
        "model = nn.Linear(X_train.shape[1], y_train.shape[1])\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for i in range(1000):\n",
        "    pred = model(X_train)\n",
        "    cost = F.mse_loss(pred, y_train)\n",
        "\n",
        "    opt.zero_grad()\n",
        "    cost.backward()\n",
        "    opt.step()\n",
        "\n",
        "    if i % 100 ==0:\n",
        "        print(\"Epoch : \",i, \"Cost\", cost.item())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :  0 Cost 1097.1541748046875\n",
            "Epoch :  100 Cost 4.582620620727539\n",
            "Epoch :  200 Cost 4.518171787261963\n",
            "Epoch :  300 Cost 4.514863967895508\n",
            "Epoch :  400 Cost 4.514693260192871\n",
            "Epoch :  500 Cost 4.51468563079834\n",
            "Epoch :  600 Cost 4.5146870613098145\n",
            "Epoch :  700 Cost 4.514686584472656\n",
            "Epoch :  800 Cost 4.51468563079834\n",
            "Epoch :  900 Cost 4.514685153961182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xQfvecHgwjz"
      },
      "source": [
        "# 3. 행렬 연산을 통한 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUFjPNDhgckQ",
        "outputId": "c7cf2451-c850-46c9-a7c2-0df060df1262"
      },
      "source": [
        "W = torch.zeros((4, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "opt = torch.optim.SGD([W,b], lr=0.01)\n",
        "\n",
        "for i in range(1000):\n",
        "    hypothesis = X_train.matmul(W) + b\n",
        "    cost = torch.mean((hypothesis - y_train)** 2)\n",
        "    opt.zero_grad()\n",
        "    cost.backward()\n",
        "    opt.step()\n",
        "\n",
        "    if i% 100 == 0:\n",
        "        print(\"Epoch : \",i, \"Cost\", cost)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :  0 Cost tensor(1075.1051, grad_fn=<MeanBackward0>)\n",
            "Epoch :  100 Cost tensor(4.5656, grad_fn=<MeanBackward0>)\n",
            "Epoch :  200 Cost tensor(4.5173, grad_fn=<MeanBackward0>)\n",
            "Epoch :  300 Cost tensor(4.5148, grad_fn=<MeanBackward0>)\n",
            "Epoch :  400 Cost tensor(4.5147, grad_fn=<MeanBackward0>)\n",
            "Epoch :  500 Cost tensor(4.5147, grad_fn=<MeanBackward0>)\n",
            "Epoch :  600 Cost tensor(4.5147, grad_fn=<MeanBackward0>)\n",
            "Epoch :  700 Cost tensor(4.5147, grad_fn=<MeanBackward0>)\n",
            "Epoch :  800 Cost tensor(4.5147, grad_fn=<MeanBackward0>)\n",
            "Epoch :  900 Cost tensor(4.5147, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCxIHGU_heLH"
      },
      "source": [
        "# 4. 행렬 X 기본 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GmNifIfg7a5",
        "outputId": "7a5fa6e8-c9b8-49d4-8457-e30625e5bc0a"
      },
      "source": [
        "w1 = torch.zeros(1, requires_grad=True)\n",
        "w2 = torch.zeros(1, requires_grad=True)\n",
        "w3 = torch.zeros(1, requires_grad=True)\n",
        "w4 = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "opt = torch.optim.SGD([w1,w2,w3,w4,b], lr = 0.01)\n",
        "\n",
        "for i in range(1000):\n",
        "    hypothesis = X_train[:,0].reshape(-1,1) * w1 + X_train[:,1].reshape(-1,1) * w2 + \\\n",
        "    X_train[:,2].reshape(-1,1) * w3 + X_train[:,3].reshape(-1,1) * w4 + b\n",
        "    cost = torch.mean((hypothesis - y_train)**2)\n",
        "\n",
        "    opt.zero_grad()\n",
        "    cost.backward()\n",
        "    opt.step()\n",
        "\n",
        "    if i% 100 == 0:\n",
        "        print(\"Epoch : \",i, \"Cost\", cost)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :  0 Cost tensor(1075.1051, grad_fn=<MeanBackward0>)\n",
            "Epoch :  100 Cost tensor(4.5656, grad_fn=<MeanBackward0>)\n",
            "Epoch :  200 Cost tensor(4.5173, grad_fn=<MeanBackward0>)\n",
            "Epoch :  300 Cost tensor(4.5148, grad_fn=<MeanBackward0>)\n",
            "Epoch :  400 Cost tensor(4.5147, grad_fn=<MeanBackward0>)\n",
            "Epoch :  500 Cost tensor(4.5147, grad_fn=<MeanBackward0>)\n",
            "Epoch :  600 Cost tensor(4.5147, grad_fn=<MeanBackward0>)\n",
            "Epoch :  700 Cost tensor(4.5147, grad_fn=<MeanBackward0>)\n",
            "Epoch :  800 Cost tensor(4.5147, grad_fn=<MeanBackward0>)\n",
            "Epoch :  900 Cost tensor(4.5147, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5Y9PquHkXr9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}